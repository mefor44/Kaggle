{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_present(file_name, head=True, na=True, info=True):\n",
    "    #file_name - name of the file (.csv)\n",
    "    #head - whether to show the first 5 rows\n",
    "    #na - whether to show if there are any miising values in dataset\n",
    "    #info - whether to show basic inforamtions about data(frame)\n",
    "\n",
    "    raw_data = pd.read_csv(file_name)\n",
    "    if info:\n",
    "        print(raw_data.info())\n",
    "    if head:\n",
    "        print(raw_data.head())\n",
    "    if na:\n",
    "        print(\"MIssing values:\\n\",raw_data.isna().sum())\n",
    "    return raw_data\n",
    "\n",
    "\n",
    "\n",
    "def fit_model_for_variable(model,variable,data):\n",
    "    train = data.dropna()\n",
    "    test = data[data[variable].isnull()].drop([variable],axis=1)\n",
    "    return model.fit(train.drop([variable],axis=1),train[variable])  \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#funkcja tworzaca zmienne typu \"dummies\"\n",
    "def getting_dummies(data,cat_variables):\n",
    "    output = pd.DataFrame()\n",
    "    for column in cat_variables:\n",
    "        encoded = pd.get_dummies(data[column],drop_first=True)\n",
    "        output = pd.concat([output,encoded],axis=1)     \n",
    "    return pd.concat([output, data.drop(cat_variables,axis=1)],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#function to make inside regression in order to  fill missing values in more robust way\n",
    "def filling_values_regression(data, variable_to_fill):\n",
    "    train = sm.add_constant(data.dropna())\n",
    "    test = sm.add_constant(data[data[variable_to_fill].isnull()].drop([variable_to_fill],axis=1))\n",
    "    lm = OLS(train[variable_to_fill],train.drop([variable_to_fill],axis=1)).fit()\n",
    "    data[variable_to_fill].fillna(value=lm.predict(test),inplace=True)\n",
    "    return data  \n",
    "\n",
    "#simple scoring fucntion for validating how many good hits classifier has got\n",
    "def score(model, data_matrix, labels):\n",
    "    predictions = [1 if (i > 0.5) else 0 for i in model.predict(data_matrix)]\n",
    "    score = sum((predictions == labels)) /len(labels)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-863e8eb21c7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#class for getting dummy variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#varibales_to_dummies - list of varibales that hase to be changhed to dummies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mgetting_dummies_01\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvariables_to_dummies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariables_to_dummies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "#class for getting dummy variables \n",
    "#varibales_to_dummies - list of varibales that hase to be changhed to dummies (HAS TO BE A LIST, even if we want to change\n",
    "#only one feature)\n",
    "class getting_dummies_01(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,variables_to_dummies):\n",
    "        self.variables = variables_to_dummies\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        output = pd.DataFrame()\n",
    "        for column in self.variables:\n",
    "            encoded = pd.get_dummies(X[column],drop_first=True,prefix=column)\n",
    "            output = pd.concat([output,encoded],axis=1)     \n",
    "        return pd.concat([output, X.drop(self.variables,axis=1)],axis=1)\n",
    "\n",
    "    \n",
    "#class for trating missing values from numerical variables\n",
    "#variable_to_fill - variable that has some missing values, this will be the respone, we will build inside regression\n",
    "#model against it\n",
    "#model - model from your choose, best idea is to use linear regression\n",
    "class filling_values_regression_method(BaseEstimator, TransformerMixin):  \n",
    "    def __init__(self,variable_to_fill,model,variable_to_drop=None):\n",
    "        self.variable = variable_to_fill\n",
    "        self.model = model\n",
    "        self.variable_to_drop = variable_to_drop\n",
    "    def fit(self, X,y=None):\n",
    "        train = X.dropna()\n",
    "        self.model = self.model.fit(train.drop([self.variable],axis=1),train[self.variable])\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        test = X[X[self.variable].isnull()].drop([self.variable],axis=1) \n",
    "        j=0\n",
    "        for i in test.index:\n",
    "            pred = self.model.predict(test.iloc[j,].to_numpy().reshape(1,-1))\n",
    "            X.loc[i,self.variable]= pred\n",
    "            j+=1\n",
    "        return X\n",
    "#it returns data frame with filled values\n",
    "\n",
    "#class for changing numerical features into categorical\n",
    "#interval- you have to specify interval, inteval = [10,30,100] - means observations lower than 10 will be transformed to 0, \n",
    "#observations between 10 and 30 will be transformed into 1,...\n",
    "#if len(interval)=p it means the feature on onutput will hasp levels ({0,1,2,...,p-1})\n",
    "class numerical_to_categorical(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, interval, variable):\n",
    "        self.interval = interval\n",
    "        self.variable = variable\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        a = X[self.variable].to_numpy() \n",
    "        for i in range(len(a)):\n",
    "            j = 0\n",
    "            while a[i]>self.interval[j]:\n",
    "                j+=1\n",
    "            a[i] = j\n",
    "        X[self.variable] = a\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "#this function is doing k-fold cross validation, with stratified sampling (we have similar populations generated)\n",
    "\n",
    "\n",
    "#model - model we wnat to check for example, logit ot linearRegression\n",
    "#metrics - scoring function (RMSE, custom make scoring fucntions)\n",
    "#Predictors - data (matrix X)\n",
    "#n_splits - how many splits we want to make\n",
    "#random state - wheter we want to use seeded ramdom number for generating\n",
    "#shuffle - wheter we want to shuffle the data\n",
    "def My_own_kfold_cross_validation(model,metrics,Predictors,labels,random_state,n_splits=5,shuffle=False):\n",
    "    stratifiedkfold = StratifiedKFold(n_splits=n_splits,random_state=random_state,shuffle=shuffle)\n",
    "    mean_score = 0 \n",
    "    for train_index, test_index in stratifiedkfold.split(X=np.zeros(len(labels)), y=labels):\n",
    "        #print(\"TRAIN:\", train_index, \"\\n\",\"TEST:\", test_index)\n",
    "        X_train, X_test = Predictors[train_index], Predictors[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        score = metrics(model.fit(X_train,y_train),data_matrix=X_test,labels=y_test)\n",
    "        #print(\"score:\",score)\n",
    "        mean_score+=score\n",
    "    return mean_score/n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
